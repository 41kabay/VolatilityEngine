{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Stochastic Volatility Forecasting\n",
    "\n",
    "## Quick Demo: Stochastic Models + Machine Learning\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **GARCH(1,1)** - Classical stochastic volatility model\n",
    "2. **ML Ensemble** - LightGBM, Random Forest, Ridge\n",
    "3. **Comparison** - Stochastic baseline vs ML predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_loader import SP500DataLoader\n",
    "from stochastic_models import GARCHModel, SimpleStochasticVol\n",
    "from feature_engineering import VolatilityFeatureEngineer, create_train_test_split\n",
    "from ml_models import VolatilityMLEnsemble\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load S&P 500 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prepared data\n",
    "loader = SP500DataLoader()\n",
    "df = loader.load_cached_data(\"sp500_prepared.csv\")\n",
    "\n",
    "print(f\"Dataset: {len(df)} samples\")\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()[:10]}...\")\n",
    "\n",
    "# Plot S&P 500 price and realized volatility\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(df.index, df['close'], linewidth=1.5)\n",
    "axes[0].set_title('S&P 500 Price', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(df.index, df['realized_vol_20'], color='red', linewidth=1.5)\n",
    "axes[1].set_title('Realized Volatility (20-period)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Volatility')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stochastic Models: GARCH(1,1)\n",
    "\n",
    "GARCH captures **volatility clustering**:\n",
    "$$\\sigma^2_t = \\omega + \\alpha \\cdot r^2_{t-1} + \\beta \\cdot \\sigma^2_{t-1}$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha$ = impact of recent shocks (news)\n",
    "- $\\beta$ = persistence of volatility\n",
    "- $\\alpha + \\beta$ close to 1 = high persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GARCH model\n",
    "garch = GARCHModel(p=1, q=1)\n",
    "garch.fit(df['returns'])\n",
    "\n",
    "# Get conditional volatility\n",
    "cond_vol = garch.get_conditional_volatility()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df.index[-len(cond_vol):], cond_vol, label='GARCH Conditional Vol', linewidth=1.5)\n",
    "plt.plot(df.index, df['realized_vol_20'], label='Realized Vol (20-period)', alpha=0.7, linewidth=1.5)\n",
    "plt.title('GARCH(1,1) Conditional Volatility vs Realized Volatility', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ GARCH parameters:\")\n",
    "print(f\"  α (alpha) = {garch.alpha:.4f} - news impact\")\n",
    "print(f\"  β (beta)  = {garch.beta:.4f} - persistence\")\n",
    "print(f\"  α + β     = {garch.alpha + garch.beta:.4f}\")\n",
    "print(f\"\\nInterpretation: {garch.alpha + garch.beta:.2%} of volatility persists to next period\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "engineer = VolatilityFeatureEngineer()\n",
    "df_features = engineer.create_all_features(df)\n",
    "\n",
    "print(f\"Original features: {len(df.columns)}\")\n",
    "print(f\"After engineering: {len(df_features.columns)}\")\n",
    "print(f\"New features created: {len(engineer.get_feature_names())}\")\n",
    "\n",
    "# Show some feature examples\n",
    "print(\"\\nExample features:\")\n",
    "for i, feat in enumerate(engineer.get_feature_names()[:15], 1):\n",
    "    print(f\"  {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train ML Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = create_train_test_split(df_features, test_size=0.2)\n",
    "\n",
    "# Further split for validation\n",
    "val_size = int(len(X_train) * 0.2)\n",
    "X_val = X_train.iloc[-val_size:]\n",
    "y_val = y_train.iloc[-val_size:]\n",
    "X_train = X_train.iloc[:-val_size]\n",
    "y_train = y_train.iloc[:-val_size]\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ensemble\n",
    "ensemble = VolatilityMLEnsemble()\n",
    "ensemble.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "results = ensemble.evaluate(X_test, y_test)\n",
    "\n",
    "# Get predictions\n",
    "ensemble_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Time series\n",
    "ax = axes[0]\n",
    "ax.plot(y_test.index, y_test.values, label='Actual', alpha=0.7, linewidth=1.5)\n",
    "ax.plot(y_test.index, ensemble_pred, label='ML Ensemble', alpha=0.7, linewidth=1.5)\n",
    "ax.set_title('ML Ensemble: Predicted vs Actual Volatility', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Volatility')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter\n",
    "ax = axes[1]\n",
    "ax.scatter(y_test, ensemble_pred, alpha=0.5, s=20)\n",
    "min_val, max_val = y_test.min(), y_test.max()\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect', linewidth=2)\n",
    "ax.set_xlabel('Actual Volatility')\n",
    "ax.set_ylabel('Predicted Volatility')\n",
    "ax.set_title('Predicted vs Actual (Scatter)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = ensemble.get_feature_importance(X_train.columns, top_n=20)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = importance_df.head(20).sort_values('importance')\n",
    "plt.barh(range(len(top_features)), top_features['importance'].values)\n",
    "plt.yticks(range(len(top_features)), top_features['feature'].values)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Top 20 Most Important Features', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Stochastic Models (GARCH)**:\n",
    "   - Captures volatility clustering\n",
    "   - Mean-reverting behavior\n",
    "   - Provides interpretable baseline\n",
    "\n",
    "2. **Machine Learning Ensemble**:\n",
    "   - Learns complex non-linear patterns\n",
    "   - Combines multiple models (LightGBM, RF, Ridge)\n",
    "   - Outperforms pure stochastic approaches\n",
    "\n",
    "3. **Applications**:\n",
    "   - **Risk Management**: Position sizing, VaR estimation\n",
    "   - **Options Trading**: Implied vs realized vol arbitrage\n",
    "   - **Portfolio Optimization**: Dynamic allocation based on vol regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final metrics summary\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nEnsemble Performance:\")\n",
    "print(f\"  MAE:  {results['ensemble']['mae']:.6f}\")\n",
    "print(f\"  RMSE: {results['ensemble']['rmse']:.6f}\")\n",
    "print(f\"  R²:   {results['ensemble']['r2']:.4f}\")\n",
    "print(f\"\\nImprovement over baseline: {results['improvement_pct']:.1f}%\")\n",
    "print(\"\\n✓ Project complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
